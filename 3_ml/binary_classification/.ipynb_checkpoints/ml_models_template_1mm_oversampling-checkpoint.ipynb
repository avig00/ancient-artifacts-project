{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fd4693",
   "metadata": {},
   "source": [
    "## load package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36f21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9f9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d474ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff73cc0",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5bb029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ricky/Desktop/sp23-ancient-artifacts-team8/3_ml/binary_classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_micro = pd.read_csv(\"../../0_data/master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39284b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a48c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro = master_micro[(master_micro['size_micro']==\"1mm\") | (master_micro['type_micro']==\"lithic\")].iloc[: , 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d566357",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e49836",
   "metadata": {},
   "source": [
    "## data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8607d",
   "metadata": {},
   "source": [
    "### Other processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns (filter1, filter2, ...)\n",
    "to_drop = micro.filter(regex='^Filter').columns\n",
    "micro = micro.drop(columns=to_drop)\n",
    "micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53958dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "micro = micro.drop(columns=['hash', 'size_micro', 'Krumbein Rnd']) #'Krumbein Rnd'\n",
    "micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a737a0",
   "metadata": {},
   "source": [
    "### Redersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c8cea",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/\n",
    "https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/\n",
    "https://towardsdatascience.com/imbalanced-classification-in-python-smote-tomek-links-method-6e48dfe69bbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a56bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc873ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro.groupby('type_micro').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the undersampling method\n",
    "undersample = SMOTE(sampling_strategy='minority')\n",
    "# undersample = TomekLinks(sampling_strategy='majority')\n",
    "# undersample = CondensedNearestNeighbour(n_neighbors=1)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "class_column = ['type_micro']\n",
    "X = micro.drop(columns=class_column)\n",
    "y = micro[class_column]\n",
    "\n",
    "X_resampled, y_resampled = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c40965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled.columns = X.columns.tolist() + ['type_micro']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aefd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled.groupby('type_micro').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate majority and minority classes\n",
    "# df_majority = micro1[micro1.type_micro=='soil']\n",
    "# df_minority = micro1[micro1.type_micro=='lithic']\n",
    "\n",
    "# # Downsample majority class\n",
    "# df_majority_downsampled = resample(df_majority, \n",
    "#                                  replace=False,    # sample without replacement\n",
    "#                                  n_samples=5299,     # to match minority class\n",
    "#                                  random_state=123) # reproducible results\n",
    " \n",
    "# # Combine minority class with downsampled majority class\n",
    "# df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25489265",
   "metadata": {},
   "source": [
    "### Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0feebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro1_selected = micro1[[\"Transparency\",\"FLength\",\"FWidth\",\"FThickness\",\"W/L Ratio\", \"L/W Ratio\", 'Sphericity', 'Circularity', 'Convexity',\"type_micro\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d38ecc",
   "metadata": {},
   "source": [
    "### Hold-out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "\n",
    "# # X is your feature data\n",
    "# # y is your target data\n",
    "# X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "\n",
    "# # Now you can perform the train-test split on X_train and y_train\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9380490",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb4b87",
   "metadata": {},
   "source": [
    "### Lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d92824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7876f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_column = ['type_micro']\n",
    "random_seed = 42\n",
    "\n",
    "features = data_resampled.drop(columns=class_column)\n",
    "target = data_resampled[class_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    stratify=data_resampled[class_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa92b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92286b87",
   "metadata": {},
   "source": [
    "### LightBGM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e0e17",
   "metadata": {},
   "source": [
    "#### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090301f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_column = ['type_micro']\n",
    "random_seed = 42\n",
    "\n",
    "features = data_resampled.drop(columns=class_column)\n",
    "target = data_resampled[class_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    stratify=data_resampled[class_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6de031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On X train: ')\n",
    "# print('X train dimensions: ', X_train.shape)\n",
    "# display(X_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn X test: ')\n",
    "# print('X test dimensions: ', X_test.shape)\n",
    "# display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a31e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On y train: ')\n",
    "# print('y train dimensions: ', y_train.shape)\n",
    "# display(y_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn y test: ')\n",
    "# print('y test dimensions: ', y_test.shape)\n",
    "# display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510084fa",
   "metadata": {},
   "source": [
    "#### Data Preprocessing - Imputation\n",
    "Not needed for imputation for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# # fill missing values with medians\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# X_train_transformed = imputer.fit_transform(X_train)\n",
    "# scale the data\n",
    "scale = StandardScaler()\n",
    "X_train_transformed = scale.fit_transform(X_train)\n",
    "\n",
    "# apply imputer and scaler to test data. But here we will not apply the\n",
    "# fit method because we do not want the model to learn anything from the test data!\n",
    "# X_test_transformed = imputer.transform(X_test)\n",
    "X_test_transformed = scale.transform(X_test)\n",
    "\n",
    "# Encode the target as well since it's categorical - we can also transform the target column using pandas\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_transformed = le.transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ec3f4",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64616bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=random_seed)\n",
    "lgbm.fit(X_train_transformed, y_train_transformed)\n",
    "print('Accuracy of LGBM classifier on training set: {:.4f}'.format(lgbm.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of LGBM classifier on test set: {:.4f}'.format(lgbm.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = lgbm.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, lgbm.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lgbm.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445badd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train1_LBGM = lgbm.score(X_train_transformed, y_train_transformed)\n",
    "acc_test1_LBGM = lgbm.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e906cd",
   "metadata": {},
   "source": [
    "#### Cross validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92405de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a08c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'num_leaves': [31, 63, 127],\n",
    "              'learning_rate': [0.1, 0.01, 0.001],\n",
    "              'n_estimators': [100, 500, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b693aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(lgbm, param_grid, cv=5)\n",
    "grid_search.fit(X_train_transformed, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a914b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22a238",
   "metadata": {},
   "source": [
    "#### Re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90850906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of LBGM classifier on training set: {:.4f}'.format(grid_search.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of LBGM classifier on test set: {:.4f}'.format(grid_search.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = grid_search.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, grid_search.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b36f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train2_LBGM = grid_search.score(X_train_transformed, y_train_transformed)\n",
    "acc_test2_LBGM = grid_search.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f9988",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = lgbm.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = data_resampled.columns[1:]\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "importance_df = pd.DataFrame({'feature_name': feature_names, 'importance': importances})\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print the top 10 features\n",
    "print(importance_df.head(10))\n",
    "\n",
    "fi_LGBM = importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ceb4e",
   "metadata": {},
   "source": [
    "### AdaBoost (Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293c29a",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e60f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_column = ['type_micro']\n",
    "random_seed = 42\n",
    "\n",
    "features = data_resampled.drop(columns=class_column)\n",
    "target = data_resampled[class_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    stratify=data_resampled[class_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebcafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On X train: ')\n",
    "# print('X train dimensions: ', X_train.shape)\n",
    "# display(X_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn X test: ')\n",
    "# print('X test dimensions: ', X_test.shape)\n",
    "# display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce053a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On y train: ')\n",
    "# print('y train dimensions: ', y_train.shape)\n",
    "# display(y_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn y test: ')\n",
    "# print('y test dimensions: ', y_test.shape)\n",
    "# display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d349da",
   "metadata": {},
   "source": [
    "#### Data Preprocessing - Imputation\n",
    "Not needed for imputation for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# # fill missing values with medians\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# X_train_transformed = imputer.fit_transform(X_train)\n",
    "# scale the data\n",
    "scale = StandardScaler()\n",
    "X_train_transformed = scale.fit_transform(X_train)\n",
    "\n",
    "# apply imputer and scaler to test data. But here we will not apply the\n",
    "# fit method because we do not want the model to learn anything from the test data!\n",
    "# X_test_transformed = imputer.transform(X_test)\n",
    "X_test_transformed = scale.transform(X_test)\n",
    "\n",
    "# Encode the target as well since it's categorical - we can also transform the target column using pandas\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_transformed = le.transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a606c8",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=random_seed)\n",
    "ada.fit(X_train_transformed, y_train_transformed)\n",
    "print('Accuracy of LGBM classifier on training set: {:.4f}'.format(ada.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of LGBM classifier on test set: {:.4f}'.format(ada.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = ada.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, ada.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ada.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c2f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train1_ada = ada.score(X_train_transformed, y_train_transformed)\n",
    "acc_test1_ada = ada.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e505fd",
   "metadata": {},
   "source": [
    "#### Cross validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bdf113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c524657",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'learning_rate': [0.1, 0.5, 1.0],\n",
    "              'algorithm': ['SAMME', 'SAMME.R']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08927bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(ada, param_grid, cv=5)\n",
    "grid_search.fit(X_train_transformed, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad774200",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3151acc",
   "metadata": {},
   "source": [
    "#### Re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3624c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of AdaBoost classifier on training set: {:.4f}'.format(grid_search.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of AdaBoost classifier on test set: {:.4f}'.format(grid_search.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = grid_search.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, grid_search.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35973078",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train2_ada = grid_search.score(X_train_transformed, y_train_transformed)\n",
    "acc_test2_ada = grid_search.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d4c23",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = ada.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = data_resampled.columns[1:]\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "importance_df = pd.DataFrame({'feature_name': feature_names, 'importance': importances})\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print the top 10 features\n",
    "print(importance_df.head(10))\n",
    "\n",
    "fi_ada = importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb823ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3332f",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd38f8",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f82287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_column = ['type_micro']\n",
    "random_seed = 42\n",
    "\n",
    "features = data_resampled.drop(columns=class_column)\n",
    "target = data_resampled[class_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    stratify=data_resampled[class_column])\n",
    "\n",
    "X_holdout = X_test\n",
    "y_holdout = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On X train: ')\n",
    "# print('X train dimensions: ', X_train.shape)\n",
    "# display(X_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn X test: ')\n",
    "# print('X test dimensions: ', X_test.shape)\n",
    "# display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On y train: ')\n",
    "# print('y train dimensions: ', y_train.shape)\n",
    "# display(y_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn y test: ')\n",
    "# print('y test dimensions: ', y_test.shape)\n",
    "# display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791242a3",
   "metadata": {},
   "source": [
    "#### Data Preprocessing - Imputation\n",
    "Not needed for imputation for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c41330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# # fill missing values with medians\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# X_train_transformed = imputer.fit_transform(X_train)\n",
    "# scale the data\n",
    "scale = StandardScaler()\n",
    "X_train_transformed = scale.fit_transform(X_train)\n",
    "\n",
    "# apply imputer and scaler to test data. But here we will not apply the\n",
    "# fit method because we do not want the model to learn anything from the test data!\n",
    "# X_test_transformed = imputer.transform(X_test)\n",
    "X_test_transformed = scale.transform(X_test)\n",
    "\n",
    "# Encode the target as well since it's categorical - we can also transform the target column using pandas\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_transformed = le.transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eaad89",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "rf = RandomForestClassifier(random_state=random_seed)\n",
    "rf.fit(X_train_transformed, y_train_transformed)\n",
    "print('Accuracy of RF classifier on training set: {:.4f}'.format(rf.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of RF classifier on test set: {:.4f}'.format(rf.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = rf.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, rf.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train1_rf = rf.score(X_train_transformed, y_train_transformed)\n",
    "acc_test1_rf = rf.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a4b90",
   "metadata": {},
   "source": [
    "#### Cross validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1388f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [10, 50, 100],\n",
    "              'max_depth': [None, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10]}\n",
    "#               'min_samples_leaf': [1, 2, 4],\n",
    "#               'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#               'max_leaf_nodes': [10, 20, 30],\n",
    "#               'class_weight':[None, 'balanced'],\n",
    "#               'criterion': ['gini', 'entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(rf, param_grid, cv=5)\n",
    "grid_search.fit(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7306960",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae11a6c",
   "metadata": {},
   "source": [
    "#### Re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Random Forest classifier on training set: {:.4f}'.format(grid_search.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of Random Forest classifier on test set: {:.4f}'.format(grid_search.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = grid_search.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, grid_search.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train2_rf = grid_search.score(X_train_transformed, y_train_transformed)\n",
    "acc_test2_rf = grid_search.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e735289",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042566c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = data_resampled.columns[1:]\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "importance_df = pd.DataFrame({'feature_name': feature_names, 'importance': importances})\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# Print the top 10 features\n",
    "print(importance_df.head(10))\n",
    "\n",
    "fi_rf = importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a26998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "plt.figure()\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aae609",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrapped Aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933a593",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_column = ['type_micro']\n",
    "random_seed = 42\n",
    "\n",
    "features = data_resampled.drop(columns=class_column)\n",
    "target = data_resampled[class_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    stratify=data_resampled[class_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On X train: ')\n",
    "# print('X train dimensions: ', X_train.shape)\n",
    "# display(X_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn X test: ')\n",
    "# print('X test dimensions: ', X_test.shape)\n",
    "# display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f1b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On y train: ')\n",
    "# print('y train dimensions: ', y_train.shape)\n",
    "# display(y_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn y test: ')\n",
    "# print('y test dimensions: ', y_test.shape)\n",
    "# display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7e2f0",
   "metadata": {},
   "source": [
    "#### Data Preprocessing - Imputation\n",
    "Not needed for imputation for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78058181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# # fill missing values with medians\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# X_train_transformed = imputer.fit_transform(X_train)\n",
    "# scale the data\n",
    "scale = StandardScaler()\n",
    "X_train_transformed = scale.fit_transform(X_train)\n",
    "\n",
    "# apply imputer and scaler to test data. But here we will not apply the\n",
    "# fit method because we do not want the model to learn anything from the test data!\n",
    "# X_test_transformed = imputer.transform(X_test)\n",
    "X_test_transformed = scale.transform(X_test)\n",
    "\n",
    "# Encode the target as well since it's categorical - we can also transform the target column using pandas\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_transformed = le.transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5f43a",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e089674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=4, random_state=random_seed)\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, random_state=random_seed)\n",
    "bagging.fit(X_train_transformed, y_train_transformed)\n",
    "print('Accuracy of LGBM classifier on training set: {:.4f}'.format(bagging.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of LGBM classifier on test set: {:.4f}'.format(bagging.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = bagging.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, bagging.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=bagging.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d66ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train1_bagging = bagging.score(X_train_transformed, y_train_transformed)\n",
    "acc_test1_bagging = bagging.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4105e7",
   "metadata": {},
   "source": [
    "#### Cross validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae11ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d230cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'max_samples': [0.5, 1.0, 2.0],\n",
    "              'max_features': [0.5, 1.0, 2.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaafceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(bagging, param_grid, cv=5)\n",
    "grid_search.fit(X_train_transformed, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbe9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8f269",
   "metadata": {},
   "source": [
    "#### Re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Bagging classifier on training set: {:.4f}'.format(grid_search.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of Bagging classifie on test set: {:.4f}'.format(grid_search.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = grid_search.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, grid_search.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train2_bagging = grid_search.score(X_train_transformed, y_train_transformed)\n",
    "acc_test2_bagging = grid_search.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59657817",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb51295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = bagging.feature_importances_\n",
    "\n",
    "# # Sort the feature importances in descending order\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# feature_names = data_resampled.columns[1:]\n",
    "# names = [feature_names[i] for i in indices]\n",
    "\n",
    "# importance_df = pd.DataFrame({'feature_name': feature_names, 'importance': importances})\n",
    "\n",
    "# # Sort the dataframe by importance\n",
    "# importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# # Print the top 10 features\n",
    "# print(importance_df.head(10))\n",
    "\n",
    "# fi_bagging = importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create plot\n",
    "# plt.figure()\n",
    "\n",
    "# # Create plot title\n",
    "# plt.title(\"Feature Importance\")\n",
    "\n",
    "# # Add bars\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# # Add feature names as x-axis labels\n",
    "# plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9178e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533bba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5494d7df",
   "metadata": {},
   "source": [
    "### SVC (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a79759e",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning libs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_column = ['type_micro']\n",
    "random_seed = 42\n",
    "\n",
    "features = data_resampled.drop(columns=class_column)\n",
    "target = data_resampled[class_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=random_seed, \n",
    "                                                    stratify=data_resampled[class_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e453f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On X train: ')\n",
    "# print('X train dimensions: ', X_train.shape)\n",
    "# display(X_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn X test: ')\n",
    "# print('X test dimensions: ', X_test.shape)\n",
    "# display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979be45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # X Train\n",
    "# print('On y train: ')\n",
    "# print('y train dimensions: ', y_train.shape)\n",
    "# display(y_train.head())\n",
    "\n",
    "# # X test\n",
    "# print('\\nOn y test: ')\n",
    "# print('y test dimensions: ', y_test.shape)\n",
    "# display(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac77be",
   "metadata": {},
   "source": [
    "#### Data Preprocessing - Imputation\n",
    "Not needed for imputation for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814c3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# # fill missing values with medians\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# X_train_transformed = imputer.fit_transform(X_train)\n",
    "# scale the data\n",
    "scale = StandardScaler()\n",
    "X_train_transformed = scale.fit_transform(X_train)\n",
    "\n",
    "# apply imputer and scaler to test data. But here we will not apply the\n",
    "# fit method because we do not want the model to learn anything from the test data!\n",
    "# X_test_transformed = imputer.transform(X_test)\n",
    "X_test_transformed = scale.transform(X_test)\n",
    "\n",
    "# Encode the target as well since it's categorical - we can also transform the target column using pandas\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_transformed = le.transform(y_train)\n",
    "y_test_transformed = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712dab5c",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4aa940",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "svc = SVC(random_state=random_seed)\n",
    "svc.fit(X_train_transformed, y_train_transformed)\n",
    "print('Accuracy of LR classifier on training set: {:.4f}'.format(svc.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of LR classifier on test set: {:.4f}'.format(svc.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = svc.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, svc.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svc.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53794aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train1_svc = svc.score(X_train_transformed, y_train_transformed)\n",
    "acc_test1_svc = svc.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde54c01",
   "metadata": {},
   "source": [
    "#### Cross validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb39816",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'rbf', 'poly'],\n",
    "              'gamma': [0.01, 0.1, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(svc, param_grid, cv=5)\n",
    "grid_search.fit(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters found: \",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca8378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(by='rank_test_score').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ab2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6544c6d",
   "metadata": {},
   "source": [
    "#### Re-run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of SV classifier on training set: {:.4f}'.format(grid_search.score(X_train_transformed, y_train_transformed)))\n",
    "print('Accuracy of SV classifie on test set: {:.4f}'.format(grid_search.score(X_test_transformed, y_test_transformed)))\n",
    "\n",
    "pred = grid_search.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test_transformed, pred))\n",
    "\n",
    "cm = confusion_matrix(y_test_transformed, grid_search.predict(X_test_transformed))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=grid_search.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train2_svc = grid_search.score(X_train_transformed, y_train_transformed)\n",
    "acc_test2_svc = grid_search.score(X_test_transformed, y_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77039d06",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = svc.feature_importances_\n",
    "\n",
    "# # Sort the feature importances in descending order\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# feature_names = data_resampled.columns[1:]\n",
    "# names = [feature_names[i] for i in indices]\n",
    "\n",
    "# importance_df = pd.DataFrame({'feature_name': feature_names, 'importance': importances})\n",
    "\n",
    "# # Sort the dataframe by importance\n",
    "# importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# # Print the top 10 features\n",
    "# print(importance_df.head(10))\n",
    "\n",
    "# fi_svc = importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create plot\n",
    "# plt.figure()\n",
    "\n",
    "# # Create plot title\n",
    "# plt.title(\"Feature Importance\")\n",
    "\n",
    "# # Add bars\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "\n",
    "# # Add feature names as x-axis labels\n",
    "# plt.xticks(range(X_train.shape[1]), names, rotation=90)\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa167c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd872e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47a8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59255d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd5f44e2",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e28f8",
   "metadata": {},
   "source": [
    "### Model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c756a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'model': ['LightGBM', 'AdaBoost', 'Random Forest', 'Bagging', 'SVC'], \n",
    "            'train_accuracy': [acc_train1_LBGM, acc_train1_ada, acc_train1_rf, acc_train1_bagging, acc_train1_svc], \n",
    "            'test_accuracy': [acc_test1_LBGM, acc_test1_ada, acc_test1_rf, acc_test1_bagging, acc_test1_svc],\n",
    "            'train_accuracy_CV': [acc_train2_LBGM, acc_train2_ada, acc_train2_rf, acc_train2_bagging, acc_train2_svc], \n",
    "            'test_accuracy_CV': [acc_test2_LBGM, acc_test2_ada, acc_test2_rf, acc_test2_bagging, acc_test2_svc]}\n",
    "\n",
    "accuracy = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.35\n",
    "\n",
    "models = np.arange(len(df['model']))\n",
    "\n",
    "plt.bar(models - bar_width/2, df['test_accuracy'], bar_width, \n",
    "        color='#FF8F45', label='test accuracy', alpha=0.9)\n",
    "plt.bar(models + bar_width/2, df['test_accuracy_CV'], bar_width, \n",
    "        color='#7CF3A0', label='test accuracy after CV', alpha=0.9)\n",
    "\n",
    "plt.xticks(models, df['model'])\n",
    "plt.ylim(0.95, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.4\n",
    "index = df.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "train_acc = ax.bar(index, df['test_accuracy'], bar_width, color='b')\n",
    "test_acc = ax.bar(index + bar_width, df['test_accuracy_CV'], bar_width, color='r')\n",
    "\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(df['model'])\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Train and Test Accuracy by Model')\n",
    "\n",
    "plt.legend((train_acc[0], test_acc[0]), ('Test Accuracy', 'Test Accuracy after CV'))\n",
    "\n",
    "for i, v in enumerate(df['test_accuracy']):\n",
    "    plt.text(i - bar_width/2, v + 0.01, format(v, '.4f'), fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "for i, v in enumerate(df['test_accuracy_CV']):\n",
    "    plt.text(i + bar_width/2, v + 0.01, format(v, '.4f'), fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8aa30",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# acc_train1_LBGM\n",
    "# acc_test1_LBGM\n",
    "\n",
    "# acc_train1_ada\n",
    "# acc_test1_ada\n",
    "\n",
    "# acc_train1_rf\n",
    "# acc_test1_rf\n",
    "\n",
    "# acc_train1_bagging\n",
    "# acc_test1_bagging\n",
    "\n",
    "# acc_train1_svc \n",
    "# acc_test1_svc\n",
    "\n",
    "# acc_train2_LBGM\n",
    "# acc_test2_LBGM\n",
    "\n",
    "# acc_train2_ada \n",
    "# acc_test2_ada \n",
    "\n",
    "# acc_train2_rf\n",
    "# acc_test2_rf\n",
    "\n",
    "# acc_train2_bagging \n",
    "# acc_test2_bagging\n",
    "\n",
    "# acc_train2_svc\n",
    "# acc_test2_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a6fb18",
   "metadata": {},
   "source": [
    "### Overall feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LGBM['importance'] = fi_LGBM['importance'] / fi_LGBM['importance'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f484232",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LGBM['rank'] = range(1, fi_LGBM.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b45199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LGBM.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313106c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LGBM = fi_LGBM[['feature_name','importance']]\n",
    "fi_LGBM = fi_LGBM.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e752594",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_ada['rank'] = range(1, fi_ada.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4182c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_ada.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_ada = fi_ada[['feature_name','importance']]\n",
    "fi_ada = fi_ada.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_rf['rank'] = range(1, fi_rf.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dbd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5345200",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_rf = fi_rf[['feature_name','importance']]\n",
    "fi_rf = fi_rf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.concat([fi_LGBM, fi_ada, fi_rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rank = fi.groupby('feature_name').mean()\n",
    "mean_rank.sort_values(by='importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cb35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_rank.reset_index(inplace=True)\n",
    "mean_rank.head(15).plot(kind='bar', x='feature_name', y='importance')\n",
    "plt.xlabel('Feature name')\n",
    "plt.ylabel('Feature importance')\n",
    "plt.title('Overall feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rank[['feature_name','importance']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "520px",
    "left": "1023px",
    "top": "111.141px",
    "width": "262.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
